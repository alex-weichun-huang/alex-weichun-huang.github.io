<!DOCTYPE HTML>
<html lang="en">
  
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Alex Huang</title>
    <meta name="author" content="Alex Huang">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
  </head>

  <body>
    <!-- All the contents -->
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">

          <!-- Intro -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>          
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
            
                <p class="name" style="text-align: center;">
                  Alex Huang
                </p>
                
                <p>
                  Hello there! My name is Alex, and I currently work as a Machine Learning Engineer at <a href="https://fetch.com/"> Fetch Rewards </a>. My research interests focus on applied deep learning, particularly in affective computing.
                </p>
  
                <p>
                  I earned my Bachelor’s degree in Computer Science from <a href="https://www.cs.wisc.edu/">UW–Madison</a>, where I had the privilege of working with <a href="https://www.biostat.wisc.edu/~yli/">Prof. Yin Li</a> and <a href="https://wid.wisc.edu/people/timothy-rogers/">Prof. Tim Rogers</a>. Starting Fall 2026, I’ll be joining the University of Michigan to work with <a href="https://emp.engin.umich.edu/">Prof. Emily Mower Provost</a>.
                </p>

                <p style="text-align:center">
                  <a href="mailto:alex.weichun.huang@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?hl=en&user=8UWkD5wAAAAJ&view_op=list_works&gmla=ALUCkoW1lpaKGD4MI-pyKzhQlf6SQNpPy9XlfVg22NGHXZIkH9lIWSWy63JNOzu8DMovFWpoz6NMfNmNfY7bhRUDHTh9IK_WHbUtVg">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/alex-huang-a1a8a91b9/">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://github.com/alex-weichun-huang">Github</a>
                </p>

              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/Alex.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/Alex.jpg" class="hoverZoomLink"></a>
              </td>
            </tr> 
          </tbody></table>

          <!-- Research Intro-->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Publications</h2>
              </td>
            </tr>
          </tbody></table>
          
          <!-- Research List -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <!-- Project 5 -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/FITW.png' width=100%>
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <span class="papertitle">A Data-driven Approach to Facial Expression Recognition</span>
                <br>
                <br>
                <strong>Wei-Chun Huang</strong> 
                <br>
                <em>Senior Thesis</em>
                <br>
                <a href="">(In Progress)</a> 
                <br>
                <p>
                  Using Transformer based VaDE model to cluster facial expressions extracted using a 3D face reconstruction model (EMOCA).
                </p>
              </td>
            </tr>
            <!-- Project 4 -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/FITW_Theory.png' width=100%>
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <span class="papertitle">Uniting theory and data: The promise and challenge of creating an honest model of facial expression</span>
                <br>
                <br>
                Sophie Wohltjen, Y. Ivette Colon, Zihao Zhu, Karina Miller, <strong>Wei-Chun Huang</strong>, Bilge Mutlu, Yin Li, Paula Niedenthal1
                <br>
                <em><strong>Cognition and Emotion</strong></em>
                <br>
                <a href=""> (In Press)</a> 
                <br>
                <p>
                  Discuss the resources that are available to help researchers build a more ecologically valid model of facial expressions. 
                </p>
              </td>
            </tr>
            <!-- Project 3 -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/Synchrony.jpg' width=100%>
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <span class="papertitle">Measuring large group synchrony and social connection with Machine Learning and Computer Vision</span>
                <br>
                <br>
                Michelle Marji, Siddharth Suresh, <strong> Wei-Chun Huang</strong>, Alexis Liu, Karina Miller, Joshua Jackson, Christian Andresen, Corey Pompey, Paula Niedenthal
                <br>
                <em><strong>Affective Science</strong></em>
                <br>
                <a href=""> (In Press)</a> 
                <br>
                <p>
                  Track and measure synchrony and spatial configurations of large groups using Faster R-CNN.
                </p>
              </td>
            </tr>
            <!-- Project 2 -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/Cat_vs_Sem.png' width=100%>
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <span class="papertitle">Categories vs Semantic Features: What shape the similarities people discern in photographs of objects?</span>
                <br>
                <br>
                Siddharth Suresh, <strong>Wei-Chun Huang</strong>, Kushin Mukherjee, Timothy Rogers
                <br>
                <em><strong>ICLR Workshop</strong></em>, 2024
                <br>
                <a href="https://openreview.net/pdf?id=iE5aXw3RFd"> paper </a> 
                <br>
                <p>
                  Discovered that model trained to produce category labels and model trained to generate
                  semantic features learned very different representational geometries throughout the network.
                </p>
              </td>
            </tr>
            <!-- Project 1 -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/LLM.png' width=100%>
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <span class="papertitle">Conceptual structure coheres in human cognition but not in Large Language Models</span>
                <br>
                <br>
                Siddharth Suresh, Kushin Mukherjee, Xizheng Yu, <strong>Wei-Chun Huang</strong>, Lisa Padua, Timothy Rogers
                <br>
                <em><strong>EMNLP</strong></em>, 2023
                <br>
                <a href="https://arxiv.org/pdf/2304.02754"> paper </a> 
                <br>
                <p>
                Compared how Large Language Models such as FLAN and GPT structure concepts relative to human cognition. 
                </p>
              </td>
            </tr>
          </tbody></table>
          
          <!-- Project Intro-->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>Other Projects</h2>
              <p>
                Below are some of the non-research projects I’ve worked on. Feel free to take a look!
              </p>
            </td>
          </tr>
          </tbody></table>
        
          <!-- Project List -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <!-- Project 2 -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/3D_Face_Feats.png' width=100%>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <span class="papertitle">3D Facial Feature Extraction</span>
              <br>
              <br>
              <a href="https://github.com/alex-weichun-huang/facial_features_3d"> repo </a> 
              <br>
              <p>
                Extract 3D Facial Features from videos and images using SOTA 3D face reconstruction model - <a href="https://github.com/radekd91/emoca">EMOCA </a>.
              </p>
            </td>
          </tr>
          <!-- Project 1 -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/Video_Feats.png' width=100%>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <span class="papertitle">Video Feature Extraction</span>
              <br>
              <br>
              <a href="https://github.com/alex-weichun-huang/video_features"> repo </a> 
              <br>
              <p>
              This directory contains the code to extract features from video datasets using mainstream vision models such as Slowfast, i3d, c3d, CLIP, etc.
              </p>
            </td>
          </tr>
          </tbody></table>

          <!-- Credits -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  This website is built using a template created by Jon Barron. You can find the source code: <a href="https://github.com/jonbarron/jonbarron_website"> here </a>. 
                </p>
              </td>
            </tr>
          </tbody></table>

        </td>
      </tr>
    </table>
  </body>
</html>
