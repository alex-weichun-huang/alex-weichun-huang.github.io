<!DOCTYPE HTML>
<html lang="en">
  
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Alex Huang</title>
    <meta name="author" content="Alex Huang">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
  </head>

  <body>
    <!-- All the contents -->
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">

          <!-- Intro -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>          
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
            
                <p class="name" style="text-align: center;">
                  Alex Huang
                </p>
                
                <p>
                  I'm a senior studying Computer Science at the University of Wisconsin-Madison with a broad interest in deep learning and multimodal learning. I have extensive hands-on experience working with models spanning across Computer Vision, NLP, and Recommendation Systems.
                </p>
                
                <p>
                  At UW-Madison, I am fortunate to work with 
                  <a href="https://www.biostat.wisc.edu/~yli/"> Prof. Yin Li </a> on video understanding tasks and  
                  <a href="https://wid.wisc.edu/people/timothy-rogers/">Prof. Tim Rogers </a> on understanding the conceptual representations of LLM.
                  I was also honored to receive the 2024 <a href="https://vision.wisc.edu/funding_opportunities/hilldale-undergraduate-fellowships/recipients/">Hilldale Research Fellowship</a>.
                </p>

                <p style="text-align:center">
                  <a href="mailto:alex.weichun.huang@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="https://drive.google.com/drive/u/0/folders/18HinqPLiotIS5dOPBZC0PYY346hQf237">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?hl=en&user=8UWkD5wAAAAJ&view_op=list_works&gmla=ALUCkoW1lpaKGD4MI-pyKzhQlf6SQNpPy9XlfVg22NGHXZIkH9lIWSWy63JNOzu8DMovFWpoz6NMfNmNfY7bhRUDHTh9IK_WHbUtVg">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/alex-huang-a1a8a91b9/">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://github.com/alex-weichun-huang">Github</a>
                </p>

              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/Alex.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/Alex.jpg" class="hoverZoomLink"></a>
              </td>
            </tr> 
          </tbody></table>

          <!-- Research Intro-->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I am currently seeking PhD opportunities with a focus on Visual Language Models and Multimodal Models. I would be excited to connect regarding any relevant opportunities!
                </p>
              </td>
            </tr>
          </tbody></table>
          
          <!-- Research List -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <!-- Project 5 -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/FITW.png' width=100%>
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <span class="papertitle">A Data-driven Approach to Reevaluate Facial Expression Categories with 3D Face Reconstruction Model and Deep Learning Clustering Algorithms</span>
                <br>
                <br>
                <strong>Wei-Chun Huang</strong> 
                <br>
                <em>Senior Thesis</em>
                <br>
                <a href="">(In Progress)</a> 
                <br>
                <p>
                  A clustering method toward Dynamic Facial Expression Recognition.
                </p>
              </td>
            </tr>
            <!-- Project 4 -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/FITW_Theory.png' width=100%>
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <span class="papertitle">Uniting theory and data: The promise and challenge of creating an honest model of facial expression</span>
                <br>
                <br>
                Sophie Wohltjen, Y. Ivette Colon, Zihao Zhu, Karina Miller, <strong>Wei-Chun Huang</strong>, Bilge Mutlu, Yin Li, Paula Niedenthal1
                <br>
                <em><strong>Cognition and Emotion</strong></em>
                <br>
                <a href=""> (In Press)</a> 
                <br>
                <p>
                  Discuss the resources that are available to help researchers build a more ecologically valid model of facial expressions. 
                </p>
              </td>
            </tr>
            <!-- Project 3 -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/Synchrony.jpg' width=100%>
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <span class="papertitle">Measuring large group synchrony and social connection with Machine Learning and Computer Vision</span>
                <br>
                <br>
                Michelle Marji, Siddharth Suresh, <strong> Wei-Chun Huang</strong>, Alexis Liu, Karina Miller, Joshua Jackson, Christian Andresen, Corey Pompey, Paula Niedenthal
                <br>
                <em><strong>Affective Science</strong></em>
                <br>
                <a href=""> (In Press)</a> 
                <br>
                <p>
                  Track and measure synchrony and spatial configurations of large groups using Machine Learning and Computer Vision. 
                </p>
              </td>
            </tr>
            <!-- Project 2 -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/Cat_vs_Sem.png' width=100%>
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <span class="papertitle">Categories vs Semantic Features: What shape the similarities people discern in photographs of objects?</span>
                <br>
                <br>
                Siddharth Suresh, <strong>Wei-Chun Huang</strong>, Kushin Mukherjee, Timothy Rogers
                <br>
                <em><strong>ICLR Workshop</strong></em>, 2024
                <br>
                <a href="https://openreview.net/pdf?id=iE5aXw3RFd"> paper </a> 
                <br>
                <p>
                  Model trained to produce category labels and model trained to generate
                  semantic features learned very different representational geometries throughout the network.
                </p>
              </td>
            </tr>
            <!-- Project 1 -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/LLM.png' width=100%>
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <span class="papertitle">Conceptual structure coheres in human cognition but not in Large Language Models</span>
                <br>
                <br>
                Siddharth Suresh, Kushin Mukherjee, Xizheng Yu, <strong>Wei-Chun Huang</strong>, Lisa Padua, Timothy Rogers
                <br>
                <em><strong>EMNLP</strong></em>, 2023
                <br>
                <a href="https://arxiv.org/pdf/2304.02754"> paper </a> 
                <br>
                <p>
                Discovered important differences between contemporary LLMs and human cognition.
                </p>
              </td>
            </tr>
          </tbody></table>
          
          <!-- Project Intro-->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>Other Projects</h2>
              <p>
                Below are some of the non-research projects Iâ€™ve worked on. Feel free to take a look!
              </p>
            </td>
          </tr>
          </tbody></table>
        
          <!-- Project List -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <!-- Project 2 -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/3D_Face_Feats.png' width=100%>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <span class="papertitle">3D Facial Feature Extraction</span>
              <br>
              <br>
              <a href="https://github.com/alex-weichun-huang/facial_features_3d"> repo </a> 
              <br>
              <p>
                Extract 3D Facial Features from videos and images using SOTA 3D face reconstruction model - <a href="https://github.com/radekd91/emoca">EMOCA </a>.
              </p>
            </td>
          </tr>
          <!-- Project 1 -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/Video_Feats.png' width=100%>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <span class="papertitle">Video Feature Extraction</span>
              <br>
              <br>
              <a href="https://github.com/alex-weichun-huang/video_features"> repo </a> 
              <br>
              <p>
              This directory contains the code to extract features from video datasets using mainstream vision models such as Slowfast, i3d, c3d, CLIP, etc.
              </p>
            </td>
          </tr>
          </tbody></table>

          <!-- Credits -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  This website is built using a template created by Jon Barron. You can find the source code: <a href="https://github.com/jonbarron/jonbarron_website"> here </a>. 
                </p>
              </td>
            </tr>
          </tbody></table>

        </td>
      </tr>
    </table>
  </body>
</html>
